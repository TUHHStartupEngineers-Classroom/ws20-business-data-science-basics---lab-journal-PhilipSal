<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Philip Salmang" />

<meta name="date" content="2020-12-06" />

<title>Journal (reproducible report)</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="site_libs/anchor-sections-1.0/anchor-sections.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">MyLabJournal</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="journal.html">Journal</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Class notes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="dictionary.html">Dictionary</a>
    </li>
    <li>
      <a href="data_wrangling.html">Data Wrangling</a>
    </li>
    <li>
      <a href="ggplot_graphs.html">ggplot graphs</a>
    </li>
    <li>
      <a href="machine_learning.html">machine learning</a>
    </li>
  </ul>
</li>
<li>
  <a href="links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Journal (reproducible report)</h1>
<h4 class="author">Philip Salmang</h4>
<h4 class="date">06 December 2020</h4>

</div>


<div id="intro-to-tidyverse" class="section level1">
<h1><span class="header-section-number">1</span> Intro to tidyverse</h1>
<p>Last compiled: 2020-12-06</p>
<p><span class="math inline">\(~\)</span></p>
<p>The goal of this introduction was to give a rough overview on how data can be transformed and visualized. Therefore, packages, pipes, tibbles and basic transformation functions were taught.</p>
<div id="challenge-1-sales-analysis" class="section level2">
<h2><span class="header-section-number">1.1</span> Challenge 1: Sales Analysis</h2>
<pre class="r"><code>library(tidyverse)
library(lubridate)
library(readxl)
# 1.0 Load and wrangle Data from excel -------------------------------------
# 1.1 import the data ----
bikes_tbl &lt;- read_excel(&quot;/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/01_bike_sales/01_raw_data/bikes.xlsx&quot;)
orderlines_tbl &lt;- read_excel(&quot;/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/01_bike_sales/01_raw_data/orderlines.xlsx&quot;)
bikeshops_tbl  &lt;- read_excel(&quot;/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/01_bike_sales/01_raw_data/bikeshops.xlsx&quot;)
# 1.2 Joining Data ----
bike_orderlines_joined_tbl &lt;- orderlines_tbl %&gt;% 
  left_join(bikes_tbl, by = c(&quot;product.id&quot; = &quot;bike.id&quot;)) %&gt;%
  left_join(bikeshops_tbl, by = c(&quot;customer.id&quot; = &quot;bikeshop.id&quot;))
# 1.3 Wrangling Data ----
bike_orderlines_wrangled_tbl &lt;- bike_orderlines_joined_tbl %&gt;%
  separate(col = location,
           into = c(&quot;city&quot;, &quot;state&quot;),
           sep = &quot;,&quot;) %&gt;% 
  separate(col = order.date,
           into = c(&quot;order.year&quot;),
           sep = &quot;-&quot;) %&gt;% 
  mutate(total_price = quantity*price)

sales_by_state &lt;- bike_orderlines_wrangled_tbl%&gt;% group_by(state) %&gt;% 
  summarize(sales = sum(total_price)) %&gt;% 
  mutate(sales_euro = scales::dollar(sales, big.mark = &quot;.&quot;,
                                     decimal.mark = &quot;,&quot;,
                                     prefix = &quot;&quot;,
                                     suffix = &quot;€ &quot;))
# 2.0 Plots ------------------------------------------
# 2.1 Bar Plot: Revenue by state ----
sales_by_state_plt &lt;-sales_by_state %&gt;%  ggplot(aes(x = state, y = sales)) + 
  geom_col(fill = &quot;#2DC6D6&quot;) + 
  labs(title = &quot;Revenue by State&quot;,
       x = &quot;&quot;, 
       y = &quot;Revenue&quot;) +
  geom_label(aes(label = sales_euro),size=2) + # Adding labels to the bars
  scale_y_continuous(labels = scales::dollar_format(big.mark = &quot;.&quot;, 
                                                    decimal.mark = &quot;,&quot;, 
                                                    prefix = &quot;&quot;, 
                                                    suffix = &quot;€&quot;)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
show(sales_by_state_plt)

# 2.2 Facet Plot: Analyze by year for each state ----

sales_by_state_year &lt;- bike_orderlines_wrangled_tbl %&gt;% group_by(order.year, state) %&gt;% 
  summarize(sales = sum(total_price))

sales_by_state_year_plt &lt;- sales_by_state_year %&gt;%
  # Set up x, y, fill
  ggplot(aes(x = order.year, y = sales, fill = state)) +
  # Geometries
  geom_col() + # Run up to here to get a stacked bar plot
  # Adding the trend
  geom_smooth(method = &quot;lm&quot;, se = FALSE) + # Adding a trendline
  # Facet
  facet_wrap(~state) +
  # Formatting
  scale_y_continuous(labels = scales::dollar_format(big.mark = &quot;.&quot;, 
                                                    decimal.mark = &quot;,&quot;, 
                                                    prefix = &quot;&quot;, 
                                                    suffix = &quot; €&quot;)) +
  # Add Title 
  labs(
    title = &quot;Revenue by year and state&quot;,
    x = &quot;&quot;,
    fill = &quot;&quot; # Changes the legend name
  )
show(sales_by_state_year_plt)</code></pre>
<p>The goal of the Challenge is to visualize the Revenue of each given state, here 12 in total. The first plot will visualize the revenue of each state in a bar plot. In the second part, 12 facet plots will be used to visualize each states revenue by year. The facet plots are helpful in order to visualize not only the revenue within each state, but a comparison between the states is also easily done.</p>
<div id="bar-plot-revenue-by-state" class="section level3">
<h3><span class="header-section-number">1.1.1</span> Bar Plot: Revenue by State</h3>
<p><img src="journal_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
</div>
<div id="revenue-analysis-from-2015-to-2019-by-state" class="section level3">
<h3><span class="header-section-number">1.1.2</span> Revenue Analysis from 2015 to 2019 by State</h3>
<p><img src="journal_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="data-acquisition" class="section level1">
<h1><span class="header-section-number">2</span> Data Acquisition</h1>
<p>Last compiled: 2020-12-06</p>
<p><span class="math inline">\(~\)</span></p>
<p>In this Chapter we learned how to acquire large amount of data either via an API or via web scrapping. Both data acquisition methods were used in the following challenges</p>
<div id="challenge-1-data-acquisition-via-api--possible-destinations-from-frankfurt-airport" class="section level2">
<h2><span class="header-section-number">2.1</span> Challenge 1: Data Acquisition via API- Possible Destinations from Frankfurt Airport</h2>
<pre class="r"><code>library(httr)
library(tidyverse)
library(jsonlite)  # converts JSON files to R objects

# 1.0 read API URL and get Data---------------------------------
url &lt;- &quot;https://aerodatabox.p.rapidapi.com/airports/icao/EDDF/stats/routes/daily&quot;
response &lt;- VERB(&quot;GET&quot;, url, add_headers(&quot;X-RapidAPI-Key&quot; = &#39;39a799b910msha3a1393a9c2d30bp1fbef4jsne313ffa56616&#39;, &quot;X-RapidAPI-Host&quot; = &#39;aerodatabox.p.rapidapi.com&#39;, &#39;&#39;), content_type(&quot;application/octet-stream&quot;))


# 2.0 Convert resonse to readable data in tables -------------------
beginning &lt;-  response %&gt;% 
  .$content %&gt;% 
  rawToChar() %&gt;% 
  fromJSON()

# 2.1 Retrieve possible destinations
daily_flights &lt;- response %&gt;% 
  .$content %&gt;% 
  rawToChar() %&gt;% 
  fromJSON() %&gt;% 
  .$routes %&gt;% 
  .$destination %&gt;% 
  select(-c(&quot;location&quot;,&quot;shortName&quot;)) %&gt;% 
  rename(&quot;City&quot; = municipalityName) %&gt;% 
  slice(1:10)
write_rds(daily_flights, &quot;daily_flights.rds&quot;)</code></pre>
<p>The API used in this challenge was the <code>aerodatabox api</code>. In order to make a more manageable plot, only the first ten destinations were plotted. A passenger traveling from Frankfurt can fly to a total of 144 destinations. There were multiple airlines departing to certain destinations. Unfortunately, I was not able to retrieve the mentioned data in the given time frame.</p>
<pre><code>##    icao iata                          name      City countryCode
## 1  EDDM  MUC                Munich, Munich    Munich          DE
## 2  LOWW  VIE             Schwechat, Vienna    Vienna          AT
## 3  EDDH  HAM              Hamburg, Hamburg   Hamburg          DE
## 4  EGLL  LHR       London Heathrow, London    London          GB
## 5  EHAM  AMS Amsterdam Schiphol, Amsterdam Amsterdam          NL
## 6  EDDB  BER    Berlin Brandenburg, Berlin    Berlin          DE
## 7  LSZH  ZRH                Kloten, Zurich    Zurich          CH
## 8  OMDB  DXB                  Dubai, Dubai     Dubai          AE
## 9  LDZA  ZAG                Zagreb, Zagreb    Zagreb          HR
## 10 EFHK  HEL     Helsinki Vantaa, Helsinki  Helsinki          FI</code></pre>
</div>
<div id="challenge-2.2-web-scraping-rosebikes.de" class="section level2">
<h2><span class="header-section-number">2.2</span> Challenge 2.2: Web Scraping Rosebikes.de</h2>
<pre class="r"><code>library(tidyverse) # Main Package - Loads dplyr, purrr, etc.
library(rvest)     # HTML Hacking &amp; Web Scraping
library(xopen)     # Quickly opening URLs
library(jsonlite)  # converts JSON files to R objects
library(glue)      # concatenate strings
library(stringi)   # character string/text processing


# 1.0 Retrieve Data form rosebikes ----
url_home_rose &lt;- &quot;https://www.rosebikes.de&quot;
html_home_rose &lt;- read_html(url_home_rose) 

# 2.0 Retrieving urls off categories ----
bike_family_url_tbl &lt;- html_home_rose %&gt;% 
  html_nodes(css = &quot;.main-navigation-category-with-tiles__item &gt; a&quot;) %&gt;% 
  html_attr(&quot;href&quot;) %&gt;%
  # remove sale category
  discard(.p = ~stringr::str_detect(.x,&quot;sale&quot;)) %&gt;%
  # make a tibble and remove family_class for better overview
  enframe(name = &quot;position&quot;, value = &quot;family_class&quot;) %&gt;%
  mutate(bike_url = glue(&quot;{url_home_rose}{family_class}&quot;)) %&gt;%
  subset(select = -family_class)

write_rds(bike_family_url_tbl, &quot;bike_family_url_tbl.rds&quot;)

# 3.0 Function to retrieve bike URLS of every single bike model using the Category URLS ---
get_all_urls &lt;- function(bike_main_url){
  
  html_bike_category &lt;- read_html(bike_main_url)
  
  bike_model_url_tbl &lt;- html_bike_category %&gt;%
    html_nodes(css = &quot;.row .align-middle &gt; a&quot;) %&gt;%
    html_attr(&quot;href&quot;) %&gt;%
    enframe(name = &quot;position&quot;, value = &quot;bike_model_url&quot;)%&gt;%
    mutate(bike_model_url = glue(&quot;{url_home_rose}{bike_model_url}&quot;))
}

# 3.1 URLs only of families as a vector
bike_family_url_vec &lt;- bike_family_url_tbl %&gt;% pull(bike_url)

# 3.2 Run the function with Family URLs as an argument to get ALL URLs
bike_model_url_lst &lt;- map(bike_family_url_vec, get_all_urls)
bike_model_url_tbl &lt;- bind_rows(bike_model_url_lst)
write_rds(bike_model_url_tbl, &quot;bike_model_url_tbl.rds&quot;)


# 4.0 Retrieve ALL prices, Model Names, Families and Models ----
# of individual bike models
get_bike_data &lt;- function(bike_url){
  html_bike &lt;- read_html(bike_url)
  
  # Fetch Bike Prices
  bike_model_price_tbl &lt;- html_bike %&gt;%
    html_nodes(css = &quot;.catalog-category-model__price-current-value&quot;) %&gt;%
    html_text() %&gt;% 
    # remove unwanted strings
    str_remove_all(pattern = &quot;\n&quot;) %&gt;% 
    str_remove_all(pattern = &quot;\\.&quot;) %&gt;% 
    str_remove_all(pattern = &quot;\\,00&quot;) %&gt;% 
    str_remove_all(pattern = &quot;\\€&quot;) %&gt;% 
    # make tibble
    enframe(name = &quot;position&quot;, value = &quot;Price_in_Euro&quot;)
  # make prices numeric
  bike_model_price_tbl$Price_in_Euro &lt;- as.numeric(as.character(bike_model_price_tbl$Price_in_Euro))
  # save prices table
  write_rds(bike_model_price_tbl, &quot;bike_model_price_tbl.rds&quot;)
  
  # Fetch Bike Model Names
  bike_model_name_tbl &lt;- html_bike %&gt;%
    html_nodes(css = &quot;.catalog-category-model__title&quot;) %&gt;%
    html_text() %&gt;%
    # remove unwanted strings
    str_remove_all(pattern = &quot;\n&quot;) %&gt;% 
    # make tibble
    enframe(name = &quot;position&quot;, value = &quot;Name&quot;)
  # save bike model names
  write_rds(bike_model_name_tbl, &quot;bike_model_name_tbl.rds&quot;)
  
  # Fetch Bike Family and Models for all bikes
  bike_fam_mod_tbl &lt;- html_bike %&gt;%
    html_nodes(css = &quot;.catalog-breadcrumb__list-item-link&quot;) %&gt;%
    html_attr(&quot;title&quot;) %&gt;%
    # make tibble
    enframe(name = &quot;position&quot;, value = &quot;Category&quot;)
  # save bike family and models
  write_rds(bike_fam_mod_tbl, &quot;bike_fam_mod_tbl.rds&quot;)
  
  # Joint Table of bike prices and names
  bike_tbl &lt;- bike_model_name_tbl %&gt;%
    left_join(bike_model_price_tbl)
  
  # Add Bike Families and Models to bike_table
  bike_tbl &lt;- bike_tbl %&gt;%
    mutate(Family = bike_fam_mod_tbl$Category[3],
           Model = bike_fam_mod_tbl$Category[4]) %&gt;%
    select(position, Family, Model, Name, Price_in_Euro)
}
# 4.1 URLs of ALL bikes
bike_model_url_vec &lt;- bike_model_url_tbl %&gt;% pull(bike_model_url)

all_bike_date_lst &lt;- map(bike_model_url_vec,get_bike_data)
all_bike_data_tbl &lt;- bind_rows(all_bike_date_lst) %&gt;% select(-c(1)) 
# Tibble of all bikes and their prices
write_rds(all_bike_data_tbl, &quot;all_bike_data_tbl.rds&quot;)</code></pre>
<p>The second way to scrap information is via web scraping. In this instance all the bike model names, and their prices were scraped from <code>rosebikes.de</code>. In order to visualize the process, the data tables will be returned with their first ten rows.</p>
<div id="step-2-get-urls-of-the-bike-categories" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Step 2: Get URLs of the Bike Categories</h3>
<p>Step 1 has not been mentioned, since we only read the <code>rosebikes.de</code>URL. In the following <code>bike_categories</code> will be mcalled <code>Family</code>! First, all URL of the individual bike families were scraped.</p>
<pre><code>## # A tibble: 10 x 2
##    position bike_url                                     
##       &lt;int&gt; &lt;glue&gt;                                       
##  1        1 https://www.rosebikes.de/fahrräder/mtb       
##  2        2 https://www.rosebikes.de/fahrräder/rennrad   
##  3        3 https://www.rosebikes.de/fahrräder/gravel    
##  4        4 https://www.rosebikes.de/fahrräder/cyclocross
##  5        5 https://www.rosebikes.de/fahrräder/fitness   
##  6        6 https://www.rosebikes.de/fahrräder/e-bike    
##  7        7 https://www.rosebikes.de/fahrräder/trekking  
##  8        8 https://www.rosebikes.de/fahrräder/reise     
##  9        9 https://www.rosebikes.de/fahrräder/urban     
## 10       10 https://www.rosebikes.de/fahrräder/kinder</code></pre>
</div>
<div id="step-3-get-urls-of-every-single-bike" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Step 3: Get URLs of every single bike</h3>
<pre class="r"><code># 3.0 Function to retrieve bike URLS of every single bike model using the Category URLS ---
get_all_urls &lt;- function(bike_main_url){
  
  html_bike_category &lt;- read_html(bike_main_url)
  
  bike_model_url_tbl &lt;- html_bike_category %&gt;%
    html_nodes(css = &quot;.row .align-middle &gt; a&quot;) %&gt;%
    html_attr(&quot;href&quot;) %&gt;%
    enframe(name = &quot;position&quot;, value = &quot;bike_model_url&quot;)%&gt;%
    mutate(bike_model_url = glue(&quot;{url_home_rose}{bike_model_url}&quot;))
}</code></pre>
<p>In this step I retrieved the URLs of all bikes. Therefore, I am able to scrap the process of every single bike on this website. Later on, the bikes <code>names</code> will be matched with their specific <code>family</code> and their <code>model</code>. Here as well, only the first ten rows will be shown.</p>
<pre><code>## # A tibble: 33 x 2
##    position bike_model_url                                                      
##       &lt;int&gt; &lt;glue&gt;                                                              
##  1        1 https://www.rosebikes.de/fahrräder/mtb/trail-/-enduro/ground-control
##  2        2 https://www.rosebikes.de/fahrräder/mtb/trail-/-enduro/root-miller   
##  3        3 https://www.rosebikes.de/fahrräder/mtb/trail-/-enduro/pikes-peak    
##  4        4 https://www.rosebikes.de/fahrräder/mtb/dirt/the-bruce               
##  5        5 https://www.rosebikes.de/fahrräder/mtb/cross-country/count-solo     
##  6        6 https://www.rosebikes.de/fahrräder/mtb/cross-country/psycho-path    
##  7        7 https://www.rosebikes.de/fahrräder/mtb/cross-country/thrill-hill    
##  8        8 https://www.rosebikes.de/fahrräder/mtb/cross-country/thrill-hill-tr…
##  9        9 https://www.rosebikes.de/fahrräder/mtb/freeride/soul-fire           
## 10        1 https://www.rosebikes.de/fahrräder/rennrad/endurance/pro-sl-disc    
## # … with 23 more rows</code></pre>
</div>
<div id="step-4-get-all-prices-model-names-and-families" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Step 4: Get all Prices, Model Names and Families</h3>
<pre class="r"><code>get_bike_data &lt;- function(bike_url){
  html_bike &lt;- read_html(bike_url)
  
  # Fetch Bike Prices
  bike_model_price_tbl &lt;- html_bike %&gt;%
    html_nodes(css = &quot;.catalog-category-model__price-current-value&quot;) %&gt;%
    html_text() %&gt;% 
    # remove unwanted strings
    str_remove_all(pattern = &quot;\n&quot;) %&gt;% 
    str_remove_all(pattern = &quot;\\.&quot;) %&gt;% 
    str_remove_all(pattern = &quot;\\,00&quot;) %&gt;% 
    str_remove_all(pattern = &quot;\\€&quot;) %&gt;% 
    # make tibble
    enframe(name = &quot;position&quot;, value = &quot;Price_in_Euro&quot;)
  # make prices numeric
  bike_model_price_tbl$Price_in_Euro &lt;- as.numeric(as.character(bike_model_price_tbl$Price_in_Euro))
  # save prices table
  write_rds(bike_model_price_tbl, &quot;bike_model_price_tbl.rds&quot;)
  
  # Fetch Bike Model Names
  bike_model_name_tbl &lt;- html_bike %&gt;%
    html_nodes(css = &quot;.catalog-category-model__title&quot;) %&gt;%
    html_text() %&gt;%
    # remove unwanted strings
    str_remove_all(pattern = &quot;\n&quot;) %&gt;% 
    # make tibble
    enframe(name = &quot;position&quot;, value = &quot;Name&quot;)
  # save bike model names
  write_rds(bike_model_name_tbl, &quot;bike_model_name_tbl.rds&quot;)
  
  # Fetch Bike Family and Models for all bikes
  bike_fam_mod_tbl &lt;- html_bike %&gt;%
    html_nodes(css = &quot;.catalog-breadcrumb__list-item-link&quot;) %&gt;%
    html_attr(&quot;title&quot;) %&gt;%
    # make tibble
    enframe(name = &quot;position&quot;, value = &quot;Category&quot;)
  # save bike family and models
  write_rds(bike_fam_mod_tbl, &quot;bike_fam_mod_tbl.rds&quot;)
  
  # Joint Table of bike prices and names
  bike_tbl &lt;- bike_model_name_tbl %&gt;%
    left_join(bike_model_price_tbl)
  
  # Add Bike Families and Models to bike_table
  bike_tbl &lt;- bike_tbl %&gt;%
    mutate(Family = bike_fam_mod_tbll$Category[3],
           Model = bike_fam_mod_tbl$Category[4]) %&gt;%
    select(position, Family, Model, Name, Price_in_Euro)
}</code></pre>
<p>Here all needed data was retrieved. This process is shown in the <code>get_bike_data</code> function. The <code>Price_in_Euro</code> of each individual bike, their main category <code>Family</code> and they model types <code>Model</code>. In the end all bikes and their specific data were merged in one table called <code>all_bike_data_tbl</code>.</p>
<pre><code>## # A tibble: 104 x 4
##    Family Model          Name             Price_in_Euro
##    &lt;chr&gt;  &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;
##  1 MTB    Trail / Enduro GROUND CONTROL 1          1699
##  2 MTB    Trail / Enduro GROUND CONTROL 2          1999
##  3 MTB    Trail / Enduro GROUND CONTROL 3          2599
##  4 MTB    Trail / Enduro GROUND CONTROL 4          3299
##  5 MTB    Trail / Enduro ROOT MILLER 1             1999
##  6 MTB    Trail / Enduro ROOT MILLER 2             2599
##  7 MTB    Trail / Enduro ROOT MILLER 3             3399
##  8 MTB    Trail / Enduro PIKES PEAK 1              3099
##  9 MTB    Trail / Enduro PIKES PEAK 2              3599
## 10 MTB    Trail / Enduro PIKES PEAK 3              4299
## # … with 94 more rows</code></pre>
</div>
</div>
</div>
<div id="data-wrangling" class="section level1">
<h1><span class="header-section-number">3</span> Data Wrangling</h1>
<p>Last compiled: 2020-12-06</p>
<pre class="r"><code>library(data.table)   # Extension of &#39;data.frame&#39; for fast manipulation of large Data 
library(tidyverse)    # Main Package - Loads dplyr, purrr, etc.
library(vroom)        # Read and Write Rectangular Text Data Quickly
library(lubridate)


# 1.0 Set up and defining columns that we are interested in ----
# 1.0.1 for files that will be read
col_types &lt;- list(
  id = col_character(),
  date = col_date(&quot;%Y-%m-%d&quot;),
  num_claims = col_double())

# 1.0.2 patent_assignee_col_types
patent_assignee_col_types &lt;- list(patent_id = col_character(),   
                                  assignee_id = col_character())

# 1.0.3 assignee_col_types
assignee_col_types &lt;- list(id = col_character(),
                           type = col_character(),
                           organization = col_character())

# 1.0.4 uspc_tbl
uspc_col_types &lt;- list(patent_id = col_character(), 
                       mainclass_id = col_character() , 
                       sequence = col_character())

## 1.1 Reading data to create tables
# 1.1.1 Creating patent_tbl
patent_tbl &lt;- vroom(
  file       = &quot;/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/Patent/raw_data/patent.tsv&quot;, 
  delim      = &quot;\t&quot;, 
  col_types  = col_types,
  na         = c(&quot;&quot;, &quot;NA&quot;, &quot;NULL&quot;)) 
setDT(patent_tbl)

# 1.1.2 Creating patent_assignee_tbl
patent_assignee_tbl &lt;- vroom(
  file       = &quot;/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/Patent/raw_data/patent_assignee.tsv&quot;, 
  delim      = &quot;\t&quot;, 
  col_types  = patent_assignee_col_types,
  na         = c(&quot;&quot;, &quot;NA&quot;, &quot;NULL&quot;))
setDT(patent_assignee_tbl)
# 1.1.3 Creating assignee_tbl
assignee_tbl &lt;- vroom(
  file       = &quot;/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/Patent/raw_data/assignee.tsv&quot;, 
  delim      = &quot;\t&quot;, 
  col_types  = assignee_col_types,
  na         = c(&quot;&quot;, &quot;NA&quot;, &quot;NULL&quot;))
setDT(assignee_tbl)

## 1.1.4 Creating uspc_tbl
uspc_tbl &lt;- vroom(
  file       = &quot;/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/Patent/raw_data/uspc.tsv&quot;, 
  delim      = &quot;\t&quot;, 
  col_types  = uspc_col_types,
  na         = c(&quot;&quot;, &quot;NA&quot;, &quot;NULL&quot;)) %&gt;%
  # remove column sequence since it is not needed
  subset(select = -sequence) 
setDT(uspc_tbl)

# make a uspc table with unique combos of patent_id and mainclass_id
uspc_unique_tbl &lt;- uspc_tbl[, .(patent_id, mainclass_id)] %&gt;% unique()

## 1.2 Merge necessary tables for extracting relevant data

# 1.2.1 Merge patent_assignee_tbl and assignee_tbl

patent_assignee_merge_dt &lt;- merge(x = assignee_tbl, y = patent_assignee_tbl,
                                  by.x = &quot;id&quot;,
                                  by.y = &quot;assignee_id&quot;)
# 1.2.2 Merge patent_assignee_merge_dt and patent_tbl;
# patent_dominance_dt used in Challenge 1 and 2 
patent_dominance_dt &lt;- merge(x = patent_assignee_merge_dt, y = patent_tbl,
                             by.x = &quot;patent_id&quot;,
                             by.y = &quot;id&quot;,
                             all.x = T, 
                             all.y = F)

# Change Date into year, month, day
patent_dominance_dt &lt;- patent_dominance_dt[, .(patent_id, 
                                               id,
                                               type,
                                               organization, 
                                               year = year(date),
                                               month = month(date),
                                               day = day(date))]

# 1.2.3 Merge patent_dominance_dt and uspc_tbl; 
# patent_dominance_innovation_dt only used in Challenge 3

patent_dominance_innovation_dt &lt;- merge(x = uspc_unique_tbl, 
                                        y = patent_dominance_dt,
                                        by = &quot;patent_id&quot;,
                                        all.x = F, 
                                        all.y = T)


## 2.0 Challenge 1, Patent Dominance: What US company / corporation has the most patents? List the ----
# 10 US companies with the most assigned/granted patents.
# include only type = 2,4,6,8,9 since these are US companies, sort by organizations
# and count the number of Patents they have. Omit any N/A values. Sort by 
# decreasing order
patent_dominance_US_dt &lt;- 
  patent_dominance_dt[!is.na(organization)][         # remove any rows containing NA 
    type %in% c(2,4,6,8,9),.N, by = organization     # Filter for US companies and count
  ][,.(Nr_Patents = N, organization)][               # Rename N 
    order(Nr_Patents, decreasing = TRUE)             # Order Nr_Patents decreasing order
  ][1:10,]                                           # slice to get first 10 companies
write_rds(patent_dominance_US_dt,&quot;patent_dominance_US_dt.rds&quot;)

## 3.0 Challenge 2, Recent patent activity: What US company had the most patents granted in July? ----
# List the top 10 companies with the most new granted patents for July. 
# include only type = 2,4,6,8,9 since these are US companies, sort by organizations
# and filter month 7 and count the number of Patents they have. 
# Omit any N/A values. Sort by decreasing order
patent_dominance_july_US_dt &lt;- 
  patent_dominance_dt[
    !is.na(organization)                             # remove any rows containing NA 
  ][month == 7,.(id, type, organization)][           # Filter for month 7
    type %in% c(2,4,6,8,9),.N, by = organization     # Filter for US companies and count 
  ][,.(Nr_Patents = N, organization)][               # Rename N 
    order(Nr_Patents,decreasing = TRUE)              # Order Nr_Patents decreasing order
  ][1:10,]                                           # slice to get first 10 companies

write_rds(patent_dominance_july_US_dt,&quot;patent_dominance_july_US_dt.rds&quot;)


## 4.0 Challenge 3, Innovation in Tech:  What is the most innovative tech sector?  ----
# For the top 10 companies (worldwide) with the most patents, 
# what are the top 5 USPTO tech main classes?

# 4.1 Extracting Top 10 Organizations with most patents
patent_dominance_world_dt &lt;- 
  patent_dominance_dt[!is.na(organization)][         # remove any rows containing NA 
    ,.N, by = organization                           # Count the amount of patents for each company
  ][,.(Nr_Patents = N, organization)][               # Rename N 
    order(Nr_Patents,decreasing = TRUE)              # Order Nr_Patents decreasing order
  ][1:10,]                                           # slice to get first 10 companies

# 4.2 Extracting Top 5 mainclass_id of Top 10 Organizations with
# patent_dominance_innovation_dt
top_mainclass &lt;- merge(x = patent_dominance_world_dt,
                       y = patent_dominance_innovation_dt,
                       by = &quot;organization&quot;) %&gt;%   
  # Remove unnecessary columns
  subset(select = -c(id, type, year, month, day, Nr_Patents)) 

# Extracting Top 5 mainclasses out of top_mainclass
top_5_mainclass &lt;- 
  top_mainclass[!is.na(mainclass_id)][               # remove any rows containing NA 
    ,.N, by = mainclass_id                           # Count the amount of each mainclass_id
  ][,
    .(Nr_mainclass = N, mainclass_id)][              # Rename N 
      order(Nr_mainclass, decreasing = TRUE)         # Order Nr_mainclass decreasing order
    ][1:5,]                                          # slice to get first 5 mainclass_id
write_rds(top_5_mainclass,&quot;top_5_mainclass.rds&quot;)</code></pre>
<p>In this chapter, the fundamentals of data wrangling and cleaning were provided. This way a nice and brief overview of large data can be given. A big part of this chapter was the introduction of <code>tibbles</code>which were used in all challenges. The entire code is given here in the beginning, but all snippets are also mentioned in the respective steps. Unfortunately, I had to work with the small data set since my laptop was not able to process the large data set. The first code given is the entire code. After that, the code snippets necessary for the respective challenge is given.</p>
<div id="preparation-of-data" class="section level2">
<h2><span class="header-section-number">3.1</span> Preparation of Data</h2>
<pre class="r"><code>library(vroom)   
# 1.0 Set up and defining columns that we are interested in ----
# 1.0.1 for files that will be read
col_types &lt;- list(
  id = col_character(),
  date = col_date(&quot;%Y-%m-%d&quot;),
  num_claims = col_double())

# 1.0.2 patent_assignee_col_types
patent_assignee_col_types &lt;- list(patent_id = col_character(),   
                                  assignee_id = col_character())

# 1.0.3 assignee_col_types
assignee_col_types &lt;- list(id = col_character(),
                           type = col_character(),
                           organization = col_character())

# 1.0.4 uspc_tbl
uspc_col_types &lt;- list(patent_id = col_character(), 
                       mainclass_id = col_character() , 
                       sequence = col_character())

## 1.1 Reading data to create tables
# 1.1.1 Creating patent_tbl
patent_tbl &lt;- vroom(
  file       = &quot;/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/Patent/raw_data/patent.tsv&quot;, 
  delim      = &quot;\t&quot;, 
  col_types  = col_types,
  na         = c(&quot;&quot;, &quot;NA&quot;, &quot;NULL&quot;)) 
setDT(patent_tbl)

# 1.1.2 Creating patent_assignee_tbl
patent_assignee_tbl &lt;- vroom(
  file       = &quot;/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/Patent/raw_data/patent_assignee.tsv&quot;, 
  delim      = &quot;\t&quot;, 
  col_types  = patent_assignee_col_types,
  na         = c(&quot;&quot;, &quot;NA&quot;, &quot;NULL&quot;))
setDT(patent_assignee_tbl)
# 1.1.3 Creating assignee_tbl
assignee_tbl &lt;- vroom(
  file       = &quot;/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/Patent/raw_data/assignee.tsv&quot;, 
  delim      = &quot;\t&quot;, 
  col_types  = assignee_col_types,
  na         = c(&quot;&quot;, &quot;NA&quot;, &quot;NULL&quot;))
setDT(assignee_tbl)

## 1.1.4 Creating uspc_tbl
uspc_tbl &lt;- vroom(
  file       = &quot;/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/Patent/raw_data/uspc.tsv&quot;, 
  delim      = &quot;\t&quot;, 
  col_types  = uspc_col_types,
  na         = c(&quot;&quot;, &quot;NA&quot;, &quot;NULL&quot;)) %&gt;%
  # remove column sequence since it is not needed
  subset(select = -sequence) 
setDT(uspc_tbl)

# make a uspc table with unique combos of patent_id and mainclass_id
uspc_unique_tbl &lt;- uspc_tbl[, .(patent_id, mainclass_id)] %&gt;% unique()

## 1.3 Merge necessary tables for extracting relevant data

# 1.3.1 Merge patent_assignee_tbl and assignee_tbl

patent_assignee_merge_dt &lt;- merge(x = assignee_tbl, y = patent_assignee_tbl,
                                  by.x = &quot;id&quot;,
                                  by.y = &quot;assignee_id&quot;)
# 1.3.2 Merge patent_assignee_merge_dt and patent_tbl;
# patent_dominance_dt used in Challenge 1 and 2 
patent_dominance_dt &lt;- merge(x = patent_assignee_merge_dt, y = patent_tbl,
                             by.x = &quot;patent_id&quot;,
                             by.y = &quot;id&quot;,
                             all.x = T, 
                             all.y = F)

# Change Date into year, month, day
patent_dominance_dt &lt;- patent_dominance_dt[, .(patent_id, 
                                               id,
                                               type,
                                               organization, 
                                               year = year(date),
                                               month = month(date),
                                               day = day(date))]

# 1.3.3 Merge patent_dominance_dt and uspc_tbl; 
# patent_dominance_innovation_dt only used in Challenge 3

patent_dominance_innovation_dt &lt;- merge(x = uspc_unique_tbl, 
                                        y = patent_dominance_dt,
                                        by = &quot;patent_id&quot;,
                                        all.x = F, 
                                        all.y = T)</code></pre>
<p>In this step, all needded data was read into the variables <code>patent_tbl</code>,<code>patent_assignee_tbl</code>,<code>assignee_tbl</code> and <code>uspc_tbl</code>. The Data was wrangled in such a way, that not needed columns were deleted and new tables were created by merging the existings tables. The specific variables needed in the upcoming challenges are mentioned inside the code.</p>
</div>
<div id="challenge-1-patent-dominance" class="section level2">
<h2><span class="header-section-number">3.2</span> Challenge 1: Patent Dominance</h2>
<pre class="r"><code>patent_dominance_US_dt &lt;- 
  patent_dominance_dt[!is.na(organization)][         # remove any rows containing NA 
    type %in% c(2,4,6,8,9),.N, by = organization     # Filter for US companies and count
  ][,.(Nr_Patents = N, organization)][               # Rename N 
    order(Nr_Patents, decreasing = TRUE)             # Order Nr_Patents decreasing order
  ][1:10,]                                           # slice to get first 10 companies</code></pre>
<p>The challenge was given as follows: “What US company / corporation has the most patents? List the 10 US companies with the most assigned/granted patents.”</p>
<p>The code in itself is explained in the code snippet. The top 10 US company/corporations are listed below.</p>
<pre><code>##     Nr_Patents                                organization
##  1:       7547 International Business Machines Corporation
##  2:       3165                       Microsoft Corporation
##  3:       2668                                 Google Inc.
##  4:       2597                       QUALCOMM Incorporated
##  5:       2201                                  Apple Inc.
##  6:       1873                    General Electric Company
##  7:       1638   Hewlett-Packard Development Company, L.P.
##  8:       1625          AT&amp;T INTELLECTUAL PROPERTY I, L.P.
##  9:       1616                           Intel Corporation
## 10:       1533         GM Global Technology Operations LLC</code></pre>
</div>
<div id="challenge-2-recent-activity" class="section level2">
<h2><span class="header-section-number">3.3</span> Challenge 2: Recent activity</h2>
<pre class="r"><code>patent_dominance_july_US_dt &lt;- 
  patent_dominance_dt[
    !is.na(organization)                             # remove any rows containing NA 
  ][month == 7,.(id, type, organization)][           # Filter for month 7
    type %in% c(2,4,6,8,9),.N, by = organization     # Filter for US companies and count 
  ][,.(Nr_Patents = N, organization)][               # Rename N 
    order(Nr_Patents,decreasing = TRUE)              # Order Nr_Patents decreasing order
  ][1:10,]                                           # slice to get first 10 companies</code></pre>
<p>The challenge was given as follows: “What US company had the most patents granted in 2019? List the top 10 companies with the most new granted patents for 2019.”</p>
<p>The code in itself is explained in the code snippet. The top 10 US companies with the most recent activity are listed below.</p>
<pre><code>##     Nr_Patents                                organization
##  1:        772 International Business Machines Corporation
##  2:        315                       Microsoft Corporation
##  3:        278                       QUALCOMM Incorporated
##  4:        254                                 Google Inc.
##  5:        219                                  Apple Inc.
##  6:        187                    General Electric Company
##  7:        176   Hewlett-Packard Development Company, L.P.
##  8:        172                           Intel Corporation
##  9:        153          AT&amp;T INTELLECTUAL PROPERTY I, L.P.
## 10:        145         GM Global Technology Operations LLC</code></pre>
</div>
<div id="challenge-3-most-innovative-main-classes" class="section level2">
<h2><span class="header-section-number">3.4</span> Challenge 3: Most Innovative Main Classes</h2>
<pre class="r"><code>patent_dominance_world_dt &lt;- 
  patent_dominance_dt[!is.na(organization)][         # remove any rows containing NA 
    ,.N, by = organization                           # Count the amount of patents for each company
  ][,.(Nr_Patents = N, organization)][               # Rename N 
    order(Nr_Patents,decreasing = TRUE)              # Order Nr_Patents decreasing order
  ][1:10,]                                           # slice to get first 10 companies

# 4.2 Extracting Top 5 mainclass_id of Top 10 Organizations with
# patent_dominance_innovation_dt
top_mainclass &lt;- merge(x = patent_dominance_world_dt,
                       y = patent_dominance_innovation_dt,
                       by = &quot;organization&quot;) %&gt;%   
  # Remove unnecessary columns
  subset(select = -c(id, type, year, month, day, Nr_Patents)) 

# Extracting Top 5 mainclasses out of top_mainclass
top_5_mainclass &lt;- 
  top_mainclass[!is.na(mainclass_id)][               # remove any rows containing NA 
    ,.N, by = mainclass_id                           # Count the amount of each mainclass_id
  ][,
    .(Nr_mainclass = N, mainclass_id)][              # Rename N 
      order(Nr_mainclass, decreasing = TRUE)         # Order Nr_mainclass decreasing order
    ][1:5,]                                          # slice to get first 5 mainclass_id</code></pre>
<p>The challenge was given as follows: “What is the most innovative tech sector? For the top 10 companies (worldwide) with the most patents, what are the top 5 USPTO tech main classes?”</p>
<p>The code in itself is explained in the code snippet. The top 5 mainclasses with are listed below</p>
<pre><code>##    Nr_mainclass mainclass_id
## 1:         2790          257
## 2:         2528          370
## 3:         2453          455
## 4:         1981          709
## 5:         1875          348</code></pre>
</div>
</div>
<div id="data-visualization" class="section level1">
<h1><span class="header-section-number">4</span> Data Visualization</h1>
<p>Last compiled: 2020-12-06</p>
<p><span class="math inline">\(~\)</span></p>
<p>In the last chapter we were introduced to the visualization of our prior acquired and wrangled data. We were given up to date Covid-19 data which we plotted in two different ways.</p>
<div id="challenge-1-line-plot--of-covid-19-cases" class="section level2">
<h2><span class="header-section-number">4.1</span> Challenge 1: Line plot- of COVID-19 cases</h2>
<pre class="r"><code>library(tidyverse)
library(readr)
library(ggthemes)
library(scales)
library(ggrepel)
library(data.table)
library(lubridate)
library(viridisLite)
library(RColorBrewer)

# 1.0 ----------------------------------------------
# read covid data
covid_data_dt &lt;- read_csv(&quot;https://opendata.ecdc.europa.eu/covid19/casedistribution/csv&quot;)

# 2.0 Wrangle Data ----------------------------------------------

# 2.1 Select appropriate columns
covid_cases &lt;- covid_data_dt %&gt;%
  select(c(1:5,&quot;countriesAndTerritories&quot;)) %&gt;%
  rename(&quot;country&quot; = &quot;countriesAndTerritories&quot;)

# 2.2 filter for countries
covid_cases_countries &lt;- covid_cases %&gt;%
  filter(country %in% c(&quot;France&quot;,&quot;Germany&quot;,&quot;Spain&quot;,&quot;United_Kingdom&quot;,&quot;United_States_of_America&quot;))

# 2.3 Cumulate Cases
covid_cumCases_countries &lt;- covid_cases_countries %&gt;%
  
  # add smart date column &amp; order
  mutate(date = str_glue(&quot;{year}-{month}-{day}&quot;) %&gt;% as.Date()) %&gt;%
  arrange(date) %&gt;%
  
  # Cumulate Cases
  group_by(country) %&gt;%
  mutate(cumCases = cumsum(cases)) %&gt;%
  ungroup() %&gt;%
  
  # Label text
  mutate(cumCases_text = scales::dollar(cumCases, big.mark = &quot;.&quot;, 
                                        decimal.mark = &quot;,&quot;, 
                                        prefix = &quot;&quot;, 
                                        suffix = &quot;&quot;))


covid_data_cum_dt &lt;- covid_cases_countries %&gt;%
  
  # add smart date column &amp; order
  mutate(date = str_glue(&quot;{year}-{month}-{day}&quot;) %&gt;% as.Date()) %&gt;%
  arrange(date) %&gt;%
  
  # Cumulate Cases
  group_by(country) %&gt;%
  mutate(cumCases = cumsum(cases)) %&gt;%
  ungroup() %&gt;%
  
  # Label text
  mutate(cumCases_text = scales::dollar(cumCases, big.mark = &quot;.&quot;, 
                                        decimal.mark = &quot;,&quot;, 
                                        prefix = &quot;&quot;, 
                                        suffix = &quot;&quot;))

# 3.0 Plot Data ----------------------------------------------
ylab &lt;- c(5.0, 10.0, 15.0) # y axis output

covid_lin_cum_plot &lt;- covid_cumCases_countries %&gt;%
  ggplot(aes(date, cumCases, color = country)) + 
  
  # Geometries
  geom_line(size = 0.5, linetype = 1) +
  geom_hline(yintercept = seq(0, 15e6, 2500000), colour=&quot;light grey&quot;) +     # horizontal net
  geom_label_repel(aes(label = cumCases_text),
                   data = covid_cumCases_countries %&gt;% filter(cumCases == max(cumCases)),
                   show.legend = F,                                                        # no label legend
                   color = &quot;white&quot;,
                   hjust = 1.5,
                   point.padding = 1e-06,                                                  # position label + line
                   fill = RColorBrewer::brewer.pal(n = 5, name = &quot;Set1&quot;)[5]            # label background = line color
  ) +
  
  
  # Formatting  
  
  scale_x_date(date_labels = &quot;%B&quot;, date_breaks = &quot;1 month&quot;) +
  
  scale_y_continuous(labels = paste0(ylab, &quot;,0 M&quot;),breaks = 10^6 * ylab) +
  scale_color_brewer(palette = &quot;Set1&quot;) +                                # color categories
  
  labs(
    title = &quot;COVID-19 confirmend cases worldwide&quot;,
    subtitle = &quot;As of 05/12/2020&quot;,
    x = expression(bold(&quot;Year 2020&quot;)),
    y = expression(bold(&quot;Cumulative Cases&quot;)),
    color = &quot;Country&quot; # Legend text 
  ) +
  
  # Theme
  theme_bw() +
  theme(legend.position  = &quot;bottom&quot;, 
        legend.direction = &quot;vertical&quot;,
        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 0.95),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_rect(fill = &quot;dark grey&quot;) 
  ) +
  guides(color=guide_legend(nrow=2, title.position = &quot;left&quot;))   </code></pre>
<p>In the following Challenge we were asked to plot the accumulated Covid-19 Cases for 5 countries <code>Germany</code>,<code>France</code>,<code>UK</code>,<code>Spain</code> and the <code>US</code> until the present day. The Graph has been matched as closely as possible to the graph given in Chapter 5.</p>
<pre class="r"><code>cases_worldwide &lt;- readRDS(&quot;covid_lin_cum_plot.rds&quot;)
cases_worldwide</code></pre>
<p><img src="journal_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
</div>
<div id="challenge-2-heat-map--worlwide-morality-rate" class="section level2">
<h2><span class="header-section-number">4.2</span> Challenge 2: Heat map- Worlwide morality rate</h2>
<pre class="r"><code># 1 DATA AQUISITION -------------------------------------------------------

library(readr)
url &lt;- &quot;https://opendata.ecdc.europa.eu/covid19/casedistribution/csv&quot;
covid_data_dt &lt;- read_csv(url)

library(maps)
world &lt;- map_data(&quot;world&quot;)


# 2 DATA WRANGLING --------------------------------------------------------

# Load packages
library(tidyverse)
library(lubridate)

# Input arguments

date &lt;- &quot;2020-12-05&quot;
date_lvl &lt;- as.Date(date)


# --- --- COVID DATA --- --- --- --- ---
# Select appropriate columns
covid_deaths &lt;- covid_data_dt %&gt;%
  select(c(1:7,&quot;countriesAndTerritories&quot;, &quot;popData2019&quot;)) %&gt;%
  rename(&quot;country&quot; = &quot;countriesAndTerritories&quot;)


# Level of deaths &amp; Mortality
covid_mort_lvl &lt;- covid_deaths %&gt;%
  
  # add smart date column &amp; order
  mutate(date = str_glue(&quot;{year}-{month}-{day}&quot;) %&gt;% as.Date()) %&gt;%
  arrange(date) %&gt;%
  
  # equalize country designations
  mutate(across(country, str_replace_all, &quot;_&quot;, &quot; &quot;)) %&gt;%
  mutate(country = case_when(country == &quot;United Kingdom&quot; ~ &quot;UK&quot;,
                             country == &quot;United States of America&quot; ~ &quot;USA&quot;,
                             country == &quot;Czechia&quot; ~ &quot;Czech Republic&quot;,
                             TRUE ~ country
                             )
         ) %&gt;%
  
  # Cumulate deaths
  group_by(country) %&gt;%
  mutate(deaths_overall = cumsum(deaths)) %&gt;%
  ungroup() %&gt;%

  # filter for desired level
  filter(date == date_lvl) %&gt;%

  # calculate mortality at level
  mutate(mortality = deaths_overall / popData2019)


# Project mortality on world 
setDT(world)
setDT(covid_mort_lvl)
covid_mort_worlwide &lt;- merge(x = covid_mort_lvl,
                              y = world, 
                              by.x = &quot;country&quot;,
                              by.y = &quot;region&quot;,
                              all.x = FALSE,
                              all.y = TRUE)
setDF(covid_mort_lvl)
  

# Writing files
write_rds(covid_cumCases_countries, &quot;covid_cumCases_countries.rds&quot;)



# 2 DATA VISUALIZATION --------------------------------------------------------------

# Load packages
library(ggplot2)
library(scales)

# Canvas
gg &lt;- ggplot()

# Geometries
gg &lt;- gg + geom_map(data = covid_mort_worlwide,
                    map  = world, 
                    aes(map_id = country, x = long, y = lat, fill= mortality),
                    colour = RColorBrewer::brewer.pal(n = 9, name = &quot;Greys&quot;)[3],
                    size=0.25)

# Formatting
gg &lt;- gg + scale_fill_gradient(low  = RColorBrewer::brewer.pal(n = 9, name = &quot;Reds&quot;)[7],
                               high = &quot;black&quot;,
                               labels = percent) +
labs(
  title    = &quot;Confirmend COVID-19 deaths relative to the size of the population&quot;,
  subtitle = &quot;More than 1.5 Million confirmend COVID-19 deaths worldwide&quot;,
  caption  = str_glue(&quot;Date:  {covid_mort_lvl[[1,1]]}&quot;),
  fill    = &quot;Mortality Rate&quot;
)

  
# Theme
gg &lt;- gg + theme_minimal() +
            theme(axis.line=element_blank(),axis.text.x=element_blank(),
                  axis.text.y=element_blank(),axis.ticks=element_blank(),
                  axis.title.x=element_blank(),
                  axis.title.y=element_blank()
                  )   </code></pre>
<p>For the last challenge we were supposed to create an heat map which represents the <code>Mortality Rate</code> of each country in the world. The <code>Mortality Rate</code> in this case is calculated as <code>Cases/Population</code>. The Code as been added as usual and the Heat map is shown below.</p>
<p><img src="05-2_map-plot_morality-rate.png" /></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
