---
title: "Journal (reproducible report)"
author: "Philip Salmang "
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: true
    toc_depth: 3
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```

**IMPORTANT:** You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.

This is an `.Rmd` file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a \# in front of your text, it will create a top level-header.

# Challenge #1

## Revenue Analysis by State 

## Revenue Analysis from 2015 to 2019 by State
```{r plot, fig.width=10, fig.height=10}
library(tidyverse)
library(lubridate)
library(readxl)
# import the data
bikes_tbl <- read_excel("/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/01_bike_sales/01_raw_data/bikes.xlsx")
orderlines_tbl <- read_excel("/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/01_bike_sales/01_raw_data/orderlines.xlsx")
bikeshops_tbl  <- read_excel("/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/01_bike_sales/01_raw_data/bikeshops.xlsx")
# 4.0 Joining Data ----
bike_orderlines_joined_tbl <- orderlines_tbl %>% 
  left_join(bikes_tbl, by = c("product.id" = "bike.id")) %>%
  left_join(bikeshops_tbl, by = c("customer.id" = "bikeshop.id"))
# 5.0 Wrangling Data ----
bike_orderlines_wrangled_tbl <- bike_orderlines_joined_tbl %>%
  separate(col = location,
           into = c("city", "state"),
           sep = ",") %>% 
  separate(col = order.date,
           into = c("order.year"),
           sep = "-") %>% 
  mutate(total_price = quantity*price)

sales_by_state <- bike_orderlines_wrangled_tbl%>% group_by(state) %>% 
  summarize(sales = sum(total_price)) %>% 
  mutate(sales_euro = scales::dollar(sales, big.mark = ".",
                                     decimal.mark = ",",
                                     prefix = "",
                                     suffix = "€ "))
# 6. Graph for sales by state
sales_by_state_plt <-sales_by_state %>%  ggplot(aes(x = state, y = sales)) + 
  geom_col(fill = "#2DC6D6") + 
  labs(title = "Revenue by State",
       x = "", 
       y = "Revenue") +
  geom_label(aes(label = sales_euro),size=2) + # Adding labels to the bars
  scale_y_continuous(labels = scales::dollar_format(big.mark = ".", 
                                                    decimal.mark = ",", 
                                                    prefix = "", 
                                                    suffix = "€")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
show(sales_by_state_plt)

# Analyze by state and by year using face_wrap

sales_by_state_year <- bike_orderlines_wrangled_tbl %>% group_by(order.year, state) %>% 
  summarize(sales = sum(total_price))

sales_by_state_year_plt <- sales_by_state_year %>%
  # Set up x, y, fill
  ggplot(aes(x = order.year, y = sales, fill = state)) +
  
  # Geometries
  geom_col() + # Run up to here to get a stacked bar plot
  # Adding the trend
  geom_smooth(method = "lm", se = FALSE) + # Adding a trendline
  # Facet
  facet_wrap(~state) +
  
  # Formatting
  scale_y_continuous(labels = scales::dollar_format(big.mark = ".", 
                                                    decimal.mark = ",", 
                                                    prefix = "", 
                                                    suffix = " €")) +
  labs(
    title = "Revenue by year and state",
    x = "",
    fill = "" # Changes the legend name
  )
show(sales_by_state_year_plt)


```


# Challenge #2
Last compiled: `r Sys.Date()`


## Challenge 2.2: Web Scraping Rosebikes.de
```{r eval = FALSE }
# 1.0 LIBRARIES ----

library(tidyverse) # Main Package - Loads dplyr, purrr, etc.
library(rvest)     # HTML Hacking & Web Scraping
library(xopen)     # Quickly opening URLs
library(jsonlite)  # converts JSON files to R objects
library(glue)      # concatenate strings
library(stringi)   # character string/text processing



url_home_rose <- "https://www.rosebikes.de"
html_home_rose <- read_html(url_home_rose) 

# 2.0 Retrieving URLs off categories
bike_family_url_tbl <- html_home_rose %>% 
  html_nodes(css = ".main-navigation-category-with-tiles__item > a") %>% 
  html_attr("href") %>%
  # remove sale category
  discard(.p = ~stringr::str_detect(.x,"sale")) %>%
  # make a tibble and remove family_class for better overview
  enframe(name = "position", value = "family_class") %>%
  mutate(bike_url = glue("{url_home_rose}{family_class}")) %>%
  subset(select = -family_class)

write_rds(bike_family_url_tbl, "bike_family_url_tbl.rds")


# 3.0 Retrieving bike URLs of every single bike model using the Familiy URLs
get_all_urls <- function(bike_main_url){
  
  html_bike_family <- read_html(bike_main_url)
  
  bike_model_url_tbl <- html_bike_family %>%
    html_nodes(css = ".row .align-middle > a") %>%
    html_attr("href") %>%
    enframe(name = "position", value = "bike_model_url")%>%
    mutate(bike_model_url = glue("{url_home_rose}{bike_model_url}"))
}

# 3.1 URLs only of families as a vector
bike_family_url_vec <- bike_family_url_tbl %>% pull(bike_url)

# 3.2 Run the function with Family URLs as an argument to get ALL URLs
bike_model_url_lst <- map(bike_family_url_vec, get_all_urls)
bike_model_url_tbl <- bind_rows(bike_model_url_lst)
write_rds(bike_model_url_tbl, "bike_model_url_tbl.rds")


# 4.0 Retrieve Families, Models, Names and Prices
# of individual bike models
get_bike_data <- function(bike_url){
  html_bike <- read_html(bike_url)
  
  # 4.1 Fetch Bike Prices
  bike_model_price_tbl <- html_bike %>%
    html_nodes(css = ".catalog-category-model__price-current-value") %>%
    html_text() %>% 
    str_remove_all(pattern = "\n") %>% 
    str_remove_all(pattern = "\\.") %>% 
    str_remove_all(pattern = "\\,00") %>% 
    str_remove_all(pattern = "\\€") %>% 
    enframe(name = "position", value = "Price_in_Euro")
  # make Price numeric
  bike_model_price_tbl$Price_in_Euro <- as.numeric(as.character(bike_model_price_tbl$Price_in_Euro))
  write_rds(bike_model_price_tbl, "bike_model_price_tbl.rds")
  
  # 4.2 Fetch Bike Names
  bike_model_name_tbl <- html_bike %>%
    html_nodes(css = ".catalog-category-model__title") %>%
    html_text() %>%
    str_remove_all(pattern = "\n") %>% 
    enframe(name = "position", value = "Name")
  write_rds(bike_model_name_tbl, "bike_model_name_tbl.rds")
  
  # 4.3 Fetch Bike Families and Models for all Bikes
  bike_category_tbl <- html_bike %>%
    html_nodes(css = ".catalog-breadcrumb__list-item-link") %>%
    html_attr("title") %>%
    enframe(name = "position", value = "Category")
  write_rds(bike_category_tbl, "bike_category_tbl.rds")
  
  # 4.5 Joint Table of bike prices and names
  bike_tbl <- bike_model_name_tbl %>%
    left_join(bike_model_price_tbl)
  
  # 4.6 Add Bike Families and Models to bike_table
  bike_tbl <- bike_tbl %>%
    mutate(Family = bike_category_tbl$Category[3],
           Model= bike_category_tbl$Category[4]) %>%
    select(position, Family, Model, Name, Price_in_Euro)
}
# URLs of ALL bikes from 3.0
bike_model_url_vec <- bike_model_url_tbl %>% pull(bike_model_url)

# Run Function to get Families, Models, Names and Prices
all_bike_date_lst <- map(bike_model_url_vec,get_bike_data)
all_bike_data_tbl <- bind_rows(all_bike_date_lst) %>% select(-c(1))
view(all_bike_data_tbl)
write_rds(all_bike_data_tbl, "all_bike_data_tbl.rds")
```


# Challenge #3

```{r eval = FALSE}
# 1.0 Libraries
library(data.table)   # Extension of 'data.frame' for fast manipulation of large Data 
library(tidyverse)    # Main Package - Loads dplyr, purrr, etc.
library(vroom)        # Read and Write Rectangular Text Data Quickly
library(lubridate)


# 2.0 Set up and defining columns that we are interested in
# 2.0.1 for files that will be read
col_types <- list(
  id = col_character(),
  date = col_date("%Y-%m-%d"),
  num_claims = col_double())

# 2.0.2 patent_assignee_col_types
patent_assignee_col_types <- list(patent_id = col_character(),   
                                  assignee_id = col_character())

# 2.0.3 assignee_col_types
assignee_col_types <- list(id = col_character(),
                           type = col_character(),
                           organization = col_character())

# 2.0.4 uspc_tbl
uspc_col_types <- list(patent_id = col_character(), 
                       mainclass_id = col_character() , 
                       sequence = col_character())

## 2.1 Reading data to create tables
# 2.1.1 Creating patent_tbl
patent_tbl <- vroom(
  file       = "/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/Patent/raw_data/patent.tsv", 
  delim      = "\t", 
  col_types  = col_types,
  na         = c("", "NA", "NULL")) 
setDT(patent_tbl)

# 2.1.2 Creating patent_assignee_tbl
patent_assignee_tbl <- vroom(
  file       = "/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/Patent/raw_data/patent_assignee.tsv", 
  delim      = "\t", 
  col_types  = patent_assignee_col_types,
  na         = c("", "NA", "NULL"))
setDT(patent_assignee_tbl)

# 2.1.3 Creating assignee_tbl
assignee_tbl <- vroom(
  file       = "/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/Patent/raw_data/assignee.tsv", 
  delim      = "\t", 
  col_types  = assignee_col_types,
  na         = c("", "NA", "NULL"))
setDT(assignee_tbl)

## 2.1.4 Creating uspc_tbl
uspc_tbl <- vroom(
  file       = "/Users/philipsalmang/Documents/R/Business Data Science Basics/DS_101/00_data/Patent/raw_data/uspc.tsv", 
  delim      = "\t", 
  col_types  = uspc_col_types,
  na         = c("", "NA", "NULL")) %>%
  # remove column sequence since it is not needed
  subset(select = -sequence) 
setDT(uspc_tbl)

# make a uspc table with unique combos of patent_id and mainclass_id
uspc_unique_tbl <- uspc_tbl[, .(patent_id, mainclass_id)] %>% unique()

## 2.3 Merge necessary tables for extracting relevant data

# 2.3.1 Merge patent_assignee_tbl and assignee_tbl

patent_assignee_merge_dt <- merge(x = assignee_tbl, y = patent_assignee_tbl,
                                  by.x = "id",
                                  by.y = "assignee_id")
# 2.3.2 Merge patent_assignee_merge_dt and patent_tbl;
# patent_dominance_dt used in Challenge 1 and 2 
patent_dominance_dt <- merge(x = patent_assignee_merge_dt, y = patent_tbl,
                             by.x = "patent_id",
                             by.y = "id",
                             all.x = T, 
                             all.y = F)

# Change Date into year, month, day
patent_dominance_dt <- patent_dominance_dt[, .(patent_id, 
                                               id,
                                               type,
                                               organization, 
                                               year = year(date),
                                               month = month(date),
                                               day = day(date))]

# 2.3.3 Merge patent_dominance_dt and uspc_tbl; 
# patent_dominance_innovation_dt only used in Challenge 3

patent_dominance_innovation_dt <- merge(x = uspc_unique_tbl, 
                                        y = patent_dominance_dt,
                                        by = "patent_id",
                                        all.x = F, 
                                        all.y = T)


## 3.0 Challenge 1, Patent Dominance: What US company / corporation has the most patents? List the 
# 10 US companies with the most assigned/granted patents.
# include only type = 2,4,6,8,9 since these are US companies, sort by organizations
# and count the number of Patents they have. Omit any N/A values. Sort by 
# decreasing order
patent_dominance_US_dt <- 
  patent_dominance_dt[!is.na(organization)][         # remove any rows containing NA 
    type %in% c(2,4,6,8,9),.N, by = organization     # Filter for US companies and count
  ][,.(Nr_Patents = N, organization)][               # Rename N 
    order(Nr_Patents, decreasing = TRUE)             # Order Nr_Patents decreasing order
  ][1:10,]                                           # slice to get first 10 companies
write_rds(patent_dominance_US_dt,"patent_dominance_US_dt.rds")

## 4.0 Challenge 2, Recent patent acitivity: What US company had the most patents granted in July? 
# List the top 10 companies with the most new granted patents for July. 
# include only type = 2,4,6,8,9 since these are US companies, sort by organizations
# and filter month 7 and count the number of Patents they have. 
# Omit any N/A values. Sort by decreasing order
patent_dominance_july_US_dt <- 
  patent_dominance_dt[
    !is.na(organization)                             # remove any rows containing NA 
  ][month == 7,.(id, type, organization)][           # Filter for month 7
    type %in% c(2,4,6,8,9),.N, by = organization     # Filter for US companies and count 
  ][,.(Nr_Patents = N, organization)][               # Rename N 
    order(Nr_Patents,decreasing = TRUE)              # Order Nr_Patents decreasing order
  ][1:10,]                                           # slice to get first 10 companies

write_rds(patent_dominance_july_US_dt,"patent_dominance_july_US_dt.rds")


## 5.0 Challenge 3, Innovation in Tech:  What is the most innovative tech sector? 
# For the top 10 companies (worldwide) with the most patents, 
# what are the top 5 USPTO tech main classes?

# 5.1 Extracting Top 10 Organizations with most patents
patent_dominance_world_dt <- 
  patent_dominance_dt[!is.na(organization)][         # remove any rows containing NA 
    ,.N, by = organization                           # Count the amount of patents for each company
  ][,.(Nr_Patents = N, organization)][               # Rename N 
    order(Nr_Patents,decreasing = TRUE)              # Order Nr_Patents decreasing order
  ][1:10,]                                           # slice to get first 10 companies

# 5.2 Extracting Top 5 mainclass_id of Top 10 Organizations with
# patent_dominance_innovation_dt
top_mainclass <- merge(x = patent_dominance_world_dt,
                       y = patent_dominance_innovation_dt,
                       by = "organization") %>%   
  # Remove unnecessary columns
  subset(select = -c(id, type, year, month, day, Nr_Patents)) 

# Extracting Top 5 mainclasses out of top_mainclass
top_5_mainclass <- 
  top_mainclass[!is.na(mainclass_id)][               # remove any rows containing NA 
    ,.N, by = mainclass_id                           # Count the amount of each mainclass_id
  ][,
    .(Nr_mainclass = N, mainclass_id)][              # Rename N 
      order(Nr_mainclass, decreasing = TRUE)         # Order Nr_mainclass decreasing order
    ][1:5,]                                          # slice to get first 5 mainclass_id
write_rds(top_5_mainclass,"top_5_mainclass.rds")
```
I'm writing this tutorial going from the top down. And, this is how it will be printed. So, notice the second post is second in the list. If you want your most recent post to be at the top, then make a new post starting at the top. If you want the oldest first, do, then keep adding to the bottom

# Adding R stuff

So far this is just a blog where you can write in plain text and serve your writing to a webpage. One of the main purposes of this lab journal is to record your progress learning R. The reason I am asking you to use this process is because you can both make a website, and a lab journal, and learn R all in R-studio. This makes everything really convenient and in the same place. 

So, let's say you are learning how to make a histogram in R. For example, maybe you want to sample 100 numbers from a normal distribution with mean = 0, and standard deviation = 1, and then you want to plot a histogram. You can do this right here by using an r code block, like this:

```{r}
samples <- rnorm(100, mean=0, sd=1)
hist(samples)
```
When you knit this R Markdown document, you will see that the histogram is printed to the page, along with the R code. This document can be set up to hide the R code in the webpage, just delete the comment (hashtag) from the cold folding option in the yaml header up top. For purposes of letting yourself see the code, and me see the code, best to keep it the way that it is. You'll learn that all of these things and more can be customized in each R code block.